{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nxtGCfvgqHrr"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "\n",
    "import scipy\n",
    "from scipy import hstack\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "#from sklearn.feature_selection.univariate_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cvt8BoiMqHr7"
   },
   "source": [
    "**Loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8697,
     "status": "ok",
     "timestamp": 1584173356944,
     "user": {
      "displayName": "Arun Singh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiLB1oZWi0vJw-6NUEFnpDZhxuDlv90nmX88O0y-A=s64",
      "userId": "01425536422013553450"
     },
     "user_tz": -330
    },
    "id": "SOEDMdj3qHsC",
    "outputId": "98e773cc-fe96-4de7-e418-b0b23d1fc6a7"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_final.csv')\n",
    "\n",
    "df_test = pd.read_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data:  (1481075, 59)\n",
      "Shape of test data:  (693359, 58)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of train data: ', df_train.shape)\n",
    "\n",
    "print('Shape of test data: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>gencat_name</th>\n",
       "      <th>subcat1_name</th>\n",
       "      <th>subcat2_name</th>\n",
       "      <th>preprocessed_name</th>\n",
       "      <th>preprocessed_description</th>\n",
       "      <th>...</th>\n",
       "      <th>gencat_mean_price</th>\n",
       "      <th>subcat1_mean_price</th>\n",
       "      <th>subcat2_mean_price</th>\n",
       "      <th>condition_mean_price</th>\n",
       "      <th>brand_median_price</th>\n",
       "      <th>name_median_price</th>\n",
       "      <th>gencat_median_price</th>\n",
       "      <th>subcat1_median_price</th>\n",
       "      <th>subcat2_median_price</th>\n",
       "      <th>condition_median_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>mlb cincinnati reds t shirt size xl</td>\n",
       "      <td>no description yet</td>\n",
       "      <td>...</td>\n",
       "      <td>34.734940</td>\n",
       "      <td>19.014216</td>\n",
       "      <td>18.368301</td>\n",
       "      <td>26.557241</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>ComputersTablets</td>\n",
       "      <td>ComponentsParts</td>\n",
       "      <td>razer blackwidow chroma keyboard</td>\n",
       "      <td>this keyboard great condition works like came ...</td>\n",
       "      <td>...</td>\n",
       "      <td>35.190558</td>\n",
       "      <td>87.970533</td>\n",
       "      <td>42.913900</td>\n",
       "      <td>26.557241</td>\n",
       "      <td>39.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>TopsBlouses</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>ava viv blouse</td>\n",
       "      <td>adorable top hint lace key hole back the pale ...</td>\n",
       "      <td>...</td>\n",
       "      <td>28.902679</td>\n",
       "      <td>18.249287</td>\n",
       "      <td>15.671262</td>\n",
       "      <td>26.499502</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>HomeDcor</td>\n",
       "      <td>HomeDcorAccents</td>\n",
       "      <td>leather horse statues</td>\n",
       "      <td>new tags leather horses retail rm stand foot h...</td>\n",
       "      <td>...</td>\n",
       "      <td>24.551068</td>\n",
       "      <td>21.581724</td>\n",
       "      <td>22.203802</td>\n",
       "      <td>26.499502</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Necklaces</td>\n",
       "      <td>24k gold plated rose</td>\n",
       "      <td>complete certificate authenticity</td>\n",
       "      <td>...</td>\n",
       "      <td>28.902679</td>\n",
       "      <td>27.516272</td>\n",
       "      <td>25.597873</td>\n",
       "      <td>26.499502</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  item_condition_id brand_name  price  shipping  gencat_name  \\\n",
       "0         0                  3    missing   10.0         1          Men   \n",
       "1         1                  3      Razer   52.0         0  Electronics   \n",
       "2         2                  1     Target   10.0         1        Women   \n",
       "3         3                  1    missing   35.0         1         Home   \n",
       "4         4                  1    missing   44.0         0        Women   \n",
       "\n",
       "       subcat1_name     subcat2_name                    preprocessed_name  \\\n",
       "0              Tops          Tshirts  mlb cincinnati reds t shirt size xl   \n",
       "1  ComputersTablets  ComponentsParts     razer blackwidow chroma keyboard   \n",
       "2       TopsBlouses           Blouse                       ava viv blouse   \n",
       "3          HomeDcor  HomeDcorAccents                leather horse statues   \n",
       "4           Jewelry        Necklaces                 24k gold plated rose   \n",
       "\n",
       "                            preprocessed_description  ... gencat_mean_price  \\\n",
       "0                                 no description yet  ...         34.734940   \n",
       "1  this keyboard great condition works like came ...  ...         35.190558   \n",
       "2  adorable top hint lace key hole back the pale ...  ...         28.902679   \n",
       "3  new tags leather horses retail rm stand foot h...  ...         24.551068   \n",
       "4                  complete certificate authenticity  ...         28.902679   \n",
       "\n",
       "   subcat1_mean_price  subcat2_mean_price  condition_mean_price  \\\n",
       "0           19.014216           18.368301             26.557241   \n",
       "1           87.970533           42.913900             26.557241   \n",
       "2           18.249287           15.671262             26.499502   \n",
       "3           21.581724           22.203802             26.499502   \n",
       "4           27.516272           25.597873             26.499502   \n",
       "\n",
       "   brand_median_price  name_median_price  gencat_median_price  \\\n",
       "0                14.0               15.5                 21.0   \n",
       "1                39.5               40.0                 15.0   \n",
       "2                12.0               14.0                 19.0   \n",
       "3                14.0               17.0                 18.0   \n",
       "4                14.0               18.0                 19.0   \n",
       "\n",
       "   subcat1_median_price  subcat2_median_price  condition_median_price  \n",
       "0                  14.0                  14.0                    16.0  \n",
       "1                  40.0                  25.0                    16.0  \n",
       "2                  14.0                  12.0                    18.0  \n",
       "3                  16.0                  16.0                    18.0  \n",
       "4                  14.0                  12.0                    18.0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>gencat_name</th>\n",
       "      <th>subcat1_name</th>\n",
       "      <th>subcat2_name</th>\n",
       "      <th>preprocessed_name</th>\n",
       "      <th>preprocessed_description</th>\n",
       "      <th>name_first</th>\n",
       "      <th>...</th>\n",
       "      <th>gencat_mean_price</th>\n",
       "      <th>subcat1_mean_price</th>\n",
       "      <th>subcat2_mean_price</th>\n",
       "      <th>condition_mean_price</th>\n",
       "      <th>brand_median_price</th>\n",
       "      <th>name_median_price</th>\n",
       "      <th>gencat_median_price</th>\n",
       "      <th>subcat1_median_price</th>\n",
       "      <th>subcat2_median_price</th>\n",
       "      <th>condition_median_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Rings</td>\n",
       "      <td>breast cancer i fight like a girl ring</td>\n",
       "      <td>size 7</td>\n",
       "      <td>breast</td>\n",
       "      <td>...</td>\n",
       "      <td>28.902679</td>\n",
       "      <td>27.516272</td>\n",
       "      <td>32.960560</td>\n",
       "      <td>26.499502</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Officesupplies</td>\n",
       "      <td>ShippingSupplies</td>\n",
       "      <td>25 pcs new 7 5 x12 kraft bubble mailers</td>\n",
       "      <td>25 pcs new 7 5 x12 kraft bubble mailers lined ...</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>20.819917</td>\n",
       "      <td>16.719531</td>\n",
       "      <td>11.275820</td>\n",
       "      <td>26.499502</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>VintageCollectibles</td>\n",
       "      <td>BagsandPurses</td>\n",
       "      <td>Handbag</td>\n",
       "      <td>coach bag</td>\n",
       "      <td>brand new coach bag bought rm coach outlet</td>\n",
       "      <td>coach</td>\n",
       "      <td>...</td>\n",
       "      <td>27.345891</td>\n",
       "      <td>61.810448</td>\n",
       "      <td>139.664714</td>\n",
       "      <td>26.499502</td>\n",
       "      <td>31.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.5</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>Women</td>\n",
       "      <td>Sweaters</td>\n",
       "      <td>Cardigan</td>\n",
       "      <td>floral kimono</td>\n",
       "      <td>floral kimono never worn lightweight perfect h...</td>\n",
       "      <td>floral</td>\n",
       "      <td>...</td>\n",
       "      <td>28.902679</td>\n",
       "      <td>26.299720</td>\n",
       "      <td>26.934284</td>\n",
       "      <td>27.584015</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>Books</td>\n",
       "      <td>ReligionSpirituality</td>\n",
       "      <td>life after death</td>\n",
       "      <td>rediscovering life loss loved one tony cooke p...</td>\n",
       "      <td>life</td>\n",
       "      <td>...</td>\n",
       "      <td>20.819917</td>\n",
       "      <td>16.209066</td>\n",
       "      <td>13.358423</td>\n",
       "      <td>26.557241</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  item_condition_id brand_name  shipping          gencat_name  \\\n",
       "0        0                  1    missing         1                Women   \n",
       "1        1                  1    missing         1                Other   \n",
       "2        2                  1      Coach         1  VintageCollectibles   \n",
       "3        3                  2    missing         0                Women   \n",
       "4        4                  3    missing         1                Other   \n",
       "\n",
       "     subcat1_name          subcat2_name  \\\n",
       "0         Jewelry                 Rings   \n",
       "1  Officesupplies      ShippingSupplies   \n",
       "2   BagsandPurses               Handbag   \n",
       "3        Sweaters              Cardigan   \n",
       "4           Books  ReligionSpirituality   \n",
       "\n",
       "                         preprocessed_name  \\\n",
       "0   breast cancer i fight like a girl ring   \n",
       "1  25 pcs new 7 5 x12 kraft bubble mailers   \n",
       "2                                coach bag   \n",
       "3                            floral kimono   \n",
       "4                         life after death   \n",
       "\n",
       "                            preprocessed_description name_first  ...  \\\n",
       "0                                             size 7     breast  ...   \n",
       "1  25 pcs new 7 5 x12 kraft bubble mailers lined ...         25  ...   \n",
       "2         brand new coach bag bought rm coach outlet      coach  ...   \n",
       "3  floral kimono never worn lightweight perfect h...     floral  ...   \n",
       "4  rediscovering life loss loved one tony cooke p...       life  ...   \n",
       "\n",
       "   gencat_mean_price  subcat1_mean_price  subcat2_mean_price  \\\n",
       "0          28.902679           27.516272           32.960560   \n",
       "1          20.819917           16.719531           11.275820   \n",
       "2          27.345891           61.810448          139.664714   \n",
       "3          28.902679           26.299720           26.934284   \n",
       "4          20.819917           16.209066           13.358423   \n",
       "\n",
       "   condition_mean_price  brand_median_price  name_median_price  \\\n",
       "0             26.499502                14.0               10.0   \n",
       "1             26.499502                14.0                8.0   \n",
       "2             26.499502                31.0               29.0   \n",
       "3             27.584015                14.0               13.0   \n",
       "4             26.557241                14.0               16.0   \n",
       "\n",
       "   gencat_median_price  subcat1_median_price  subcat2_median_price  \\\n",
       "0                 19.0                  14.0                  15.0   \n",
       "1                 14.0                  11.0                   9.0   \n",
       "2                 16.0                  28.0                  55.5   \n",
       "3                 19.0                  20.0                  17.0   \n",
       "4                 14.0                  11.0                  11.0   \n",
       "\n",
       "   condition_median_price  \n",
       "0                    18.0  \n",
       "1                    18.0  \n",
       "2                    18.0  \n",
       "3                    17.0  \n",
       "4                    16.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train, Test split for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(df_train['price'])\n",
    "X=df_train.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (1184860, 58), CV size: (296215, 58), Test size: (693359, 58)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_cv , y_train, y_cv = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train size: {}, CV size: {}, Test size: {}' .format(x_train.shape, x_cv.shape, df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Categorical features\n",
    "\n",
    "* One-hot encoding of brand_name, gencat_name, subcat1_name, subcat2_name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_category(categorical_values):\n",
    "    '''takes categorical column values as arguments and returns list of cleaned categories'''\n",
    "    \n",
    "    catogories = list(categorical_values)\n",
    "\n",
    "    categorical_values_list = []\n",
    "    for i in tqdm(catogories):\n",
    "        i = re.sub('[^A-Za-z0-9]+', ' ', i)\n",
    "        i = i.replace(' ','')\n",
    "        i = i.replace('&','_')\n",
    "        categorical_values_list.append(i.strip())\n",
    "    \n",
    "    return categorical_values_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 1184860/1184860 [00:03<00:00, 391476.96it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 296215/296215 [00:00<00:00, 381151.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 693359/693359 [00:01<00:00, 397183.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#Cleaning brand name before using count vectorizer\n",
    "# Using same preprocessing as used earlier for categories: 'clean_cat()' function\n",
    "\n",
    "x_train['brand_name'] = clean_category(x_train['brand_name'].values)\n",
    "\n",
    "x_cv['brand_name'] = clean_category(x_cv['brand_name'].values)\n",
    "\n",
    "df_test['brand_name'] = clean_category(df_test['brand_name'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrices after one hot encoding\n",
      "(1184860, 4509) \n",
      " (296215, 4509) \n",
      " (693359, 4509)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False, binary=True)\n",
    "vectorizer.fit(x_train['brand_name'].values)\n",
    "\n",
    "train_brand_oneHot = vectorizer.transform(x_train['brand_name'].values)\n",
    "\n",
    "cv_brand_oneHot = vectorizer.transform(x_cv['brand_name'].values)\n",
    "\n",
    "test_brand_oneHot = vectorizer.transform(df_test['brand_name'].values)\n",
    "\n",
    "print(\"Shape of matrices after one hot encoding\")\n",
    "\n",
    "print(train_brand_oneHot.shape, \"\\n\", cv_brand_oneHot.shape  ,\"\\n\", test_brand_oneHot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrices after one hot encoding\n",
      "(1184860, 11) \n",
      " (296215, 11) \n",
      " (693359, 11)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False, binary=True)\n",
    "vectorizer.fit(x_train['gencat_name'].values)\n",
    "\n",
    "train_gencat_oneHot = vectorizer.transform(x_train['gencat_name'].values)\n",
    "\n",
    "cv_gencat_oneHot = vectorizer.transform(x_cv['gencat_name'].values)\n",
    "\n",
    "test_gencat_oneHot = vectorizer.transform(df_test['gencat_name'].values)\n",
    "\n",
    "print(\"Shape of matrices after one hot encoding\")\n",
    "\n",
    "print(train_gencat_oneHot.shape, \"\\n\", cv_gencat_oneHot.shape, \"\\n\", test_gencat_oneHot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrices after one hot encoding\n",
      "(1184860, 114) \n",
      " (296215, 114) \n",
      " (693359, 114)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False, binary=True)\n",
    "vectorizer.fit(x_train['subcat1_name'].values)\n",
    "\n",
    "train_subcat1_oneHot = vectorizer.transform(x_train['subcat1_name'].values)\n",
    "\n",
    "cv_subcat1_oneHot = vectorizer.transform(x_cv['subcat1_name'].values)\n",
    "\n",
    "test_subcat1_oneHot = vectorizer.transform(df_test['subcat1_name'].values)\n",
    "\n",
    "print(\"Shape of matrices after one hot encoding\")\n",
    "print(train_subcat1_oneHot.shape, \"\\n\", cv_subcat1_oneHot.shape, \"\\n\", test_subcat1_oneHot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrices after one hot encoding\n",
      "(1184860, 860) \n",
      " (296215, 860) \n",
      " (693359, 860)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(lowercase=False, binary=True)\n",
    "vectorizer.fit(x_train['subcat2_name'].values)\n",
    "\n",
    "train_subcat2_oneHot = vectorizer.transform(x_train['subcat2_name'].values)\n",
    "\n",
    "cv_subcat2_oneHot = vectorizer.transform(x_cv['subcat2_name'].values)\n",
    "\n",
    "test_subcat2_oneHot = vectorizer.transform(df_test['subcat2_name'].values)\n",
    "\n",
    "print(\"Shape of matrices after one hot encoding\")\n",
    "print(train_subcat2_oneHot.shape, \"\\n\", cv_subcat2_oneHot.shape, \"\\n\", test_subcat2_oneHot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf vectorization on text features\n",
    "\n",
    "* 1-3 grams of name<br>\n",
    "\n",
    "* 1-3 grams of item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrices after vectorization\n",
      "(1184860, 250000) \n",
      " (296215, 250000) \n",
      " (693359, 250000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=3, max_features=250000)\n",
    "vectorizer.fit(x_train['preprocessed_name'].values)\n",
    "\n",
    "train_name_tfidf = vectorizer.transform(x_train['preprocessed_name'].values)\n",
    "\n",
    "cv_name_tfidf = vectorizer.transform(x_cv['preprocessed_name'].values)\n",
    "\n",
    "test_name_tfidf = vectorizer.transform(df_test['preprocessed_name'].values.astype('U'))\n",
    "\n",
    "print(\"Shape of matrices after vectorization\")\n",
    "print(train_name_tfidf.shape, \"\\n\", cv_name_tfidf.shape, \"\\n\", test_name_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrices after vectorization\n",
      "(1184860, 500000) \n",
      " (296215, 500000) \n",
      " (693359, 500000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=5, max_features=500000)\n",
    "vectorizer.fit(x_train['preprocessed_description'].values)\n",
    "\n",
    "train_description_tfidf = vectorizer.transform(x_train['preprocessed_description'].values)\n",
    "\n",
    "cv_description_tfidf = vectorizer.transform(x_cv['preprocessed_description'].values)\n",
    "\n",
    "test_description_tfidf = vectorizer.transform(df_test['preprocessed_description'].values.astype('U'))\n",
    "\n",
    "print(\"Shape of matrices after vectorization\")\n",
    "print(train_description_tfidf.shape, \"\\n\", cv_description_tfidf.shape, \"\\n\", test_description_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing following columns: \n",
      "  {'desc_word_count', 'NameUpper', 'DescriptionPunctCount', 'gencat_mean_price', 'brand_name_count', 'DescriptionUpperRatio', 'mean_name', 'DescriptionUpper', 'weird_characters_name', 'name_desc_len_ratio', 'stopword_ratio_desc', 'NameDigitCount', 'subcat1_name_count', 'subcat1_mean_price', 'des_len', 'subcat2_median_price', 'NameUpperRatio', 'DescriptionLowerRatio', 'num_sum', 'prices_count', 'subcat2_name_count', 'mean_des', 'name_word_count', 'gencat_name_count', 'brand_median_price', 'gencat_median_price', 'condition_mean_price', 'name_first_count', 'name_len', 'subcat1_median_price', 'brand_mean_price', 'NamePunctCount', 'DescriptionLower', 'NameLowerRatio', 'NamePunctCountRatio', 'DescriptionDigitCount', 'name_letters_per_word', 'name_mean_price', 'name_median_price', 'condition_median_price', 'NameDigitCountRatio', 'DescriptionDigitCountRatio', 'weird_characters_desc', 'subcat2_mean_price', 'DescriptionPunctCountRatio', 'NameLower', 'desc_letters_per_word'}\n"
     ]
    }
   ],
   "source": [
    "cols = set(x_train.columns.values) - {'train_id'}\n",
    "\n",
    "skip_cols = {'preprocessed_name', 'item_condition_id', 'brand_name',\n",
    "  'shipping', 'preprocessed_description', 'gencat_name',\n",
    "  'subcat1_name', 'subcat2_name', 'name_first', 'price_in_name'}\n",
    "\n",
    "cols_to_normalize = cols - skip_cols\n",
    "print(\"Normalizing following columns: \\n \", cols_to_normalize)\n",
    "\n",
    "def normalize(df):\n",
    "    result1 = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if (feature_name in cols_to_normalize):\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            result1[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_normalized = normalize(x_train)\n",
    "\n",
    "cv_normalized = normalize(x_cv)\n",
    "\n",
    "test_normalized = normalize(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove non-features from dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating and storing all numerical features\n",
    "\n",
    "X_tr = train_normalized[list(cols_to_normalize)]\n",
    "X_val = cv_normalized[list(cols_to_normalize)]\n",
    "X_te = test_normalized[list(cols_to_normalize)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_temp=pd.get_dummies(train_normalized[['item_condition_id', 'shipping', 'price_in_name']], sparse=True)\n",
    "x_cv_temp=pd.get_dummies(cv_normalized[['item_condition_id', 'shipping', 'price_in_name']], sparse=True)\n",
    "x_test_temp=pd.get_dummies(test_normalized[['item_condition_id', 'shipping', 'price_in_name']], sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1184860, 3) (296215, 3) (693359, 3)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Storing categorical features to sparse matrix\n",
    "\n",
    "X_tr_cat = csr_matrix(x_tr_temp.values , dtype=np.int8)\n",
    "\n",
    "X_cv_cat = csr_matrix(x_cv_temp.values, dtype=np.int8)\n",
    "\n",
    "X_te_cat = csr_matrix(x_test_temp.values , dtype=np.int8)\n",
    "\n",
    "print(X_tr_cat.shape, X_cv_cat.shape, X_te_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Consolidate all features to a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# stack all categorical and text sparse matrices\n",
    "\n",
    "train_sparse = hstack((train_brand_oneHot, train_gencat_oneHot, train_subcat1_oneHot, train_subcat2_oneHot, \\\n",
    "               train_name_tfidf, train_description_tfidf, X_tr_cat)).tocsr()\n",
    "\n",
    "cv_sparse = hstack((cv_brand_oneHot, cv_gencat_oneHot, cv_subcat1_oneHot, cv_subcat2_oneHot, \\\n",
    "               cv_name_tfidf, cv_description_tfidf, X_cv_cat)).tocsr()\n",
    "\n",
    "test_sparse = hstack((test_brand_oneHot, test_gencat_oneHot, test_subcat1_oneHot, test_subcat2_oneHot, \\\n",
    "               test_name_tfidf, test_description_tfidf, X_te_cat)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1184860, 755497) (296215, 755497) (693359, 755497)\n"
     ]
    }
   ],
   "source": [
    "print(train_sparse.shape, cv_sparse.shape, test_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack dense feature matrix with categorical and text vectors\n",
    "\n",
    "X_train = hstack((X_tr.values, train_sparse)).tocsr()\n",
    "\n",
    "X_cv = hstack((X_val.values, cv_sparse)).tocsr()\n",
    "\n",
    "X_test = hstack((X_te.values, test_sparse)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train size: (1184860, 755544), X_CV size: (296215, 755544), X_Test size: (693359, 755544)\n"
     ]
    }
   ],
   "source": [
    "print('X_Train size: {}, X_CV size: {}, X_Test size: {}' .format(X_train.shape, X_cv.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_Train size: (1184860,), y_CV size: (296215,)\n"
     ]
    }
   ],
   "source": [
    "print('y_Train size: {}, y_CV size: {}' .format(y_train.shape, y_cv.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxu9IDJDqHt2"
   },
   "source": [
    "### 4. LightGBM Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LltDSSWNqHuJ"
   },
   "source": [
    "#### Training and testing using best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywxA4pCbqHuL",
    "outputId": "85b85d12-49f4-44ba-f901-529b32f7a98a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(learning_rate=0.3745401188473625, max_depth=14,\n",
       "              min_child_weight=0.3668695797323276, n_estimators=1395,\n",
       "              num_leaves=40, random_state=42, subsample=0.9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(learning_rate=0.3745401188473625, max_depth=14,\n",
    "              min_child_weight=0.3668695797323276, n_estimators=1395,\n",
    "              num_leaves=40, random_state=42, subsample=0.9, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KAv4add1qHuT",
    "outputId": "d97e8cd7-6a8e-44c5-8d3d-07b5ff96e8c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSLE: 0.367618141036234\n",
      "Cross validation RMSLE:  0.429925315705115\n"
     ]
    }
   ],
   "source": [
    "lgb_preds_tr = model.predict(X_train)\n",
    "lgb_preds_cv = model.predict(X_cv)\n",
    "\n",
    "\n",
    "print('Train RMSLE:', sqrt(mse(y_train, lgb_preds_tr)))\n",
    "\n",
    "print(\"Cross validation RMSLE: \", sqrt(mse(y_cv, lgb_preds_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_preds_te = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.65666576, 2.94559861, 4.33771795, 3.05841033, 2.49436811,\n",
       "       2.69120987, 2.90589221, 3.98698268, 4.17450297, 2.61740287])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted price\n",
    "lgb_preds_te[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.08535089, 3.57037173, 2.6698779 , 3.38802678, 2.88470724,\n",
       "       2.77345203, 2.69827774, 2.52460266, 3.04061196, 2.74620167])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted price\n",
    "lgb_preds_te[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74392025, 2.83698055, 3.19565149, ..., 2.67891744, 2.75119776,\n",
       "       2.89376643])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted price\n",
    "lgb_preds_te[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mercari_advModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
